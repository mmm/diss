
\chapter{Conclusions}
\label{chap:conclusion}
\index{Conclusion@\emph{Conclusion}}%


In discussing results, the first thing to note is that
a quantum computer sure would have been useful in actually
performing this simulation.
As Feynman noted\cite{Feynman:82}, simulating a quantum system
by a classical computer requires an exponentially large amount
of overhead.  This was clearly evident in this research.

Decoherence and the 
experimental control and manipulation of different 
physical devices introduce noise into a computation.  
How much noise can the computation withstand before
it fails?  Exactly how does a computation fail in the
presence of various types of noise?
Any means of getting a handle
on the stability of these algorithms warrants attention.

The current work uses a numerical simulation of
a dynamical description of Grover's quantum search
algorithm to determine the answers to some of these
questions.

\pagebreak
%--------------------------------------------------------------------------------   
%--------------------------------------------------------------------------------   
\section{The Effects of Noise on Grover's Algorithm}

Noise does not slow the algorithm down.  It only reduces the
probability that the algorithm will succeed.  This is shown in 
figure \ref{fig:humps}.
\begin{figure}[h]
\begin{center}
\epsfig{file=figures/humps.pstex,height=3.5in,width=4.5in}
\end{center}
\caption{Probability of success -v- time for different noise levels and different numbers
of qubits.  Black is a run without noise, red is the same run with noise.  Notice that
where the peaks occur in ``time'' do not change due to noise.  The relative times of the
peaks are artificial in this graph.}
\label{fig:humps}
\end{figure}

\pagebreak

\noindent
Define the maximum amount of noise that the algorithm can tolerate
as the point at which the probability of success falls below $\frac{1}{2}$.
For $n$ qubits,
this maximum amount of tolerable noise falls off as $\frac{1}{n^3}$, 
as shown in figure \ref{fig:results}.
\begin{figure}[h]
\begin{center}
\epsfig{file=figures/max-noise.pstex,height=3.5in,width=4.5in}
\end{center}
\caption{Maximum tolerable noise as a function of the number of qubits.
This curve is approximately fit by $y = 0.5812 x^{-2.886}$.}
\label{fig:results}
\end{figure}
%y = 0.58123479 N^{-2.886221}

\pagebreak

\noindent
Appendix \ref{chap:data} contains:
\begin{itemize}
\item Bures-v-time for different noise levels and different numbers of qubits.
\item Maximum probability of success -v- noise level for given number of qubits.
\item Maximum probability of success -v- number of qubits for given noise levels.
\end{itemize}


%--------------------------------------------------------------------------------   
%--------------------------------------------------------------------------------   
\section{Topics for Further Investigation}

\begin{enumerate}
\item How does quantum error correction help?  
Consider, for instance, digitized sound stored on an audio 
compact disk.
A huge majority of the information stored on such a CD consists of 
coding and methods to prevent errors in
digital data from destroying the audio content of
the CD.
Little of this information would be necessary without noise.
Well, a similar kind of redundancy can be built around quantum information.
Quantum errors can be corrected.

My results determine how much noise the bare algorithm can tolerate.
Experimentalists
would like to know to what tolerances they need to control candidate
technologies for qubits.
A more interesting result for them, the so--called bottom line, would be
how much noise, not the bare algorithm, but the algorithm \emph{with
error correction} can tolerate.

It also may be interesting to determine explicitly how device 
noise corresponds to ``bit flips'' in the quantum error 
correction literature.

\item How can decoherence--free subspaces help?  Little is known about
the geometry of the space of states of a quantum system.  Investigation
into this geometry yields decoherence--free regions of 
state\cite{Kempe/Bacon/Lidar/Whaley:00}.  Can this be harnessed by,
not necessarily exact, but more robust versions of certain quantum
algorithms?

\item Can a Hamiltonian be produced for Grover's algorithm?  Can this
be used for a more analytical stability analysis?  Can error correction
be added to this?

\item Can other algorithms such as Shor's be treated dynamically?
\end{enumerate}
