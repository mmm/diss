

\chapter{Quantum Algorithms}
\label{chap:quantumAlgorithms}
\index{Quantum Algorithms@\emph{Quantum Algorithms}}%

A quantum algorithm is a set of states and operations performed
with a quantum computer in order to arrive at an answer to a particular
specified problem.
There are no simple prescriptions for contructing a quantum algorithm.
There are no rules by which one can take an existing classical algorithm,
an algorithm developed to run on a classical computer, and construct
a corresponding quantum algorithm.  There are not even many tools or concepts
used in developing classical algorithms that carry over into the quantum
domain.

As discussed in Chapter \ref{chap:quantumComputation}, 
the advent of universal quantum gates
allows the representation of any computable function on a 
quantum computer.  However, the uniquely quantum operations that 
must be performed 
require a wider range of tricks to be used when developing
algorithms to be run on a quantum computer.

Despite the difficulty involved, there have been a few, seemingly
inspired, algorithms developed for a quantum computer.
In fact, the entire field essentially owes its existence to 
an algorithm developed by Peter Shor\cite{Shor:94,Shor:00}
to solve FACTORIZATION\footnote{The convention, originating in computer 
science, of YELLING the proper names of particular problems to be solved 
will be followed throughout this text.}, where the quantum version 
enjoys an \emph{exponential} speedup over the classical.  
The discovery of this algorithm has reduced the complexity class of 
this problem, a feat to which many in computer science aspire.

The following sections outline several aspects of quantum
algorithms.  A few existing algorithms are described, along
with the basic framework needed to determine their computational
complexity.  An approach to possible new algorithms is then 
discussed.

%--------------------------------------------------------------------------------   
%--------------------------------------------------------------------------------   
\section{Simple Quantum Algorithms}

%--------------------------------------------------------------------------------   
\subsection{Deutsch's Algorithm}

Deutsch\cite{Deutsch:?} gives a simple example of a problem that
can be solved faster on a quantum computer than its classical
counterpart.
Consider some black box that evaluates a function 
$f\colon\lbrace 0,1\rbrace\to\lbrace 0,1\rbrace$,
where each evaluation, for whatever reason, 
takes a long period of time to compute, say 24 hours.
The problem is to determine, as quickly as possible, 
information about the function
using only inputs and outputs of the black box.

The obvious approach is to simply set an input value,
then read the output value when the computation is done
(24 hours later).  Do this for all possible input values
($0$ or $1$), then, 48 hours later, you have all possible 
information about the function.

What if that time is not good enough?  Even if we are only 
interested in limited information about the function, 
such as is it \emph{constant} $\left( f(0) = f(1) \right)$ or
\emph{balanced} $\left( f(0) \ne f(1) \right)$, it would still
require full function evaluation (48 hours).

Is there a quicker way?  Yes, if there exists a quantum
black box that computes $f(x)$, then the problem can be solved
with a single function evaluation.  

First, insure reversability of the computation, even if the 
quantum black box itself is
not reversible, by constructing the unitary transformation
\begin{equation}
U_f\colon \ket{x}\ket{y} \to \ket{x}\ket{y\oplus f(x)},
\end{equation}
where the second bit is flipped if $f(x)=1$ and left alone
if $f(x)=0$.
Just as in the classical case, this computer can determine
if the function is constant or balanced with multiple evaluations
of $f(x)$.  Still taking 48 hours to arrive at an answer.

Because the black box is a quantum computer, it can accept
as an input a superposition of states $\ket{0}$ and $\ket{1}$.
If the second qubit is initially prepared in the state
$\frac{1}{\sqrt{2}}\left( \ket{0} - \ket{1} \right)$, then
\begin{equation}
\begin{split}
U_f\colon \ket{x}\otimes\frac{1}{\sqrt{2}}\left( \ket{0} - \ket{1} \right)
\quad\to&\quad\ket{x}\otimes\frac{1}{\sqrt{2}}\bigl(\ket{f(x)} - \ket{1\oplus f(x)}\bigr)\\
=&\quad\ket{x}\otimes(-1)^{f(x)}\frac{1}{\sqrt{2}}\left( \ket{0} - \ket{1} \right).
\end{split}
\end{equation}
Now, prepare the first qubit in the superposition 
$\frac{1}{\sqrt{2}}\left( \ket{0} + \ket{1} \right)$.
The black box now acts
\begin{multline}
U_f\colon \frac{1}{\sqrt{2}}\left( \ket{0} + \ket{1} \right)
        \otimes\frac{1}{\sqrt{2}}\left( \ket{0} - \ket{1} \right) \quad\to\\
        \frac{1}{\sqrt{2}}\bigl( (-1)^{f(0)}\ket{0} + (-1)^{f(1)}\ket{1} \bigr)
        \otimes\frac{1}{\sqrt{2}}\left( \ket{0} - \ket{1} \right).
\end{multline}
Now, we simply perform a measurement that projects the first qubit into
the basis
\begin{equation}
\ket{\pm} = \frac{1}{\sqrt{2}}\left( \ket{0} \pm \ket{1} \right),
\end{equation}
to learn, after a single function evaluation, that the function is
balanced if you measure $\ket{+}$, constant if $\ket{-}$.

So, here, the quantum computer gets an answer in around 24 hours, where
the classical one would require 48.  This speedup is attributed to
the concept of \emph{quantum parallelism}.  The quantum computer is not
limited to computing just a single $f(0)$ or $f(1)$ at a time, but in acting on
superpositions of states, it behaves as if there were a sort of 
parallelism in execution.  The computer essentially evaluates all inputs
at the same time, storing the information in correlations between the states
that make up the input and output registers.  This information
is only really available via specifically prepared measurements, but it is
there.  The output of the quantum computation does encode this ``global''
information about the function.

The quantum circuit to compute Deutsch's algorithm is shown in figure
(\ref{fig:deutsch}).
\begin{figure}[h]
\begin{center}
\begin{picture}(100,50)
    \put(10,0){\framebox(20,20){\bf{$H$}}}
    \put(10,30){\framebox(20,20){\bf{$H$}}}
    \put(70,30){\framebox(20,20){\bf{$H$}}}
    \put(40,0){\framebox(20,20){\bf{$U_f$}}}
    \put(-20,7){$\ket{x}$}
    \put(-20,37){$\ket{0}$}
    \put(110,7){\text{Trash}}
    \put(110,37){\text{Measure}}
    \put(50,40){\circle*{4}}
    \path(0,10)(10,10)
    \path(30,10)(40,10)
    \path(60,10)(100,10)
    \path(0,40)(10,40)
    \path(30,40)(70,40)
    \path(90,40)(100,40)
    \path(50,20)(50,40)
\end{picture}
\caption{Deutsch's circuit}
\label{fig:deutsch}
\end{center}
\end{figure}


\subsubsection{The Deutsch--Jozsa Algorithm}
\label{ss:deutschJosza}

Of course, the simple function $\lbrace 0,1\rbrace\to\lbrace 0,1\rbrace$
discussed above is not particularly useful for anything other than
providing a simple example with which to exhibit a quantum algorithm.
However, the same principles apply to a more useful function
$f\colon\lbrace 0,1\rbrace^N\to\lbrace 0,1\rbrace$.
Again, construct the unitary operator
\begin{equation}
U_f\colon\ket{x}\ket{0}\to\ket{x}\ket{f(x)}.
\end{equation}
Then, via a Hadamard tranformation ({\it c.f.}, chapter
(\ref{chap:quantumComputation})), choose the input register to 
be in the state
\begin{equation}
\left[\frac{1}{\sqrt{2}}\left(\ket{0}+\ket{1}\right)\right]^N
= \frac{1}{2^{N/2}}\sum_{x=0}^{2^N-1}\ket{x}.
\end{equation}
A single function evaluation leaves 
\begin{equation}
    \frac{1}{2^{N/2}}\sum_{x=0}^{2^N-1}\ket{x}\ket{f(x)},
\end{equation}
which encodes ``global'' information about the function.
The trick is to now extract this information via specialized
measurements.


Consider the classical version of the above computation.
Depending on what sort of information we are trying to obtain
about the function, there are \emph{many}(!) function evaluations
required.  For $N\gg 1$, this quickly becomes intractable. 
The quantum case required only one.  For obvious reasons, this is 
considered ``massive quantum parallelism'' in the literature.

%--------------------------------------------------------------------------------   
\subsection{Simon's Algorithm}

In the last section it was shown how quantum algorithms can
exhibit a speedup over algorithms designed to run on a classical
computer.  How much faster can certain problems be solved?
Do the problems remain in the same complexity class ({\it c.f.},
chapter (\ref{chap:quantumComputation})), or like for Shor's 
algorithm, will the quantum algorithm change the actual 
complexity class of the problem?

Simon's algorithm\cite{Simon:97} 
is the simplest algorithm where the problem to
be solved is classically \emph{hard}, but can be computed in
polynomial time on a quantum computer.

Consider a function 
\begin{equation}
f\colon\lbrace 0,1\rbrace^n\to\lbrace 0,1\rbrace^n
\end{equation}
that is 2--to--1 and periodic when viewed as a map 
$\left(\Z_2\right)^n\to\left(\Z_2\right)^n$
(as opposed to $\Z_{2^n}\to\Z_{2^n}$).
\ie, If the period of $f$ is $a$, then
\begin{equation}
f(x) = f(x\oplus a).
\end{equation}
The problem is: given a quantum black box that evaluates such a function,
find its period.

This problem is classically hard\footnote{According to Shor\cite{Shor:00}},
because the function will need to be evaluated an exponentially large number
of times to find $a$.
\mmm{prove this}

The quantum solution to the problem starts with two zero registers
\begin{equation}
\ket{0}\ket{0}.
\end{equation}
Now prepare an equally weighted superposition of all $n$-bit strings
in the first register by using the Hadamaard transformation
\begin{equation}
\left(H\otimes\bf{1}\right)\ket{0}\ket{0} =
\left(\frac{1}{\sqrt{2^n}}\sum_{x=0}^{2^n-1}\ket{x}\right)\ket{0},
\end{equation}
and then query the oracle
\begin{equation}
U_f\colon\quad
\frac{1}{\sqrt{2^n}}\sum_{x=0}^{2^n-1}\ket{x}\ket{0}\quad\mapsto\quad
\frac{1}{\sqrt{2^n}}\sum_{x=0}^{2^n-1}\ket{x}\ket{f(x)}.
\end{equation}
Now, a measurement of the second register, let's say it is measured
to be in the state $\ket{c}$,
will collapse the first register into a superposition of all 
states $\ket{x_0}$ such that $f(x_0)=c$.  
For the function specified in this algorithm, 
there are two such values, $x_0$ and $x_0\oplus a$.
After the measurement of the second register, 
the first register then should look like 
\begin{equation}
\frac{1}{\sqrt{2}}\bigl(\ket{x_0}+\ket{x_0\oplus a}\bigr).
\end{equation}
Note that, at this point, a measurement of this first register tells
nothing about $a$.  However, taking another Hadamaard transformation 
(see equation \ref{e:generalHadamaard})
on the first register gives 
\begin{equation}
H \frac{1}{\sqrt{2}}\bigl(\ket{x_0}+\ket{x_0\oplus a}\bigr)=
\,\frac{1}{\sqrt{2^{n+1}}}\sum_{y=0}^{2^n-1}
\biggl[(-1)^{x_0\cdot y}+(-1)^{(x_0\oplus a)\cdot y}\biggr]\ket{y}.
\end{equation}
This is non--zero only for $a\cdot y=0$, and so the first register
can then be rewritten as
\begin{equation}
H \frac{1}{\sqrt{2}}\bigl(\ket{x_0}+\ket{x_0\oplus a}\bigr)
=\frac{1}{\sqrt{2^{n-1}}}\sum_{a\cdot y=0}
(-1)^{x_0\cdot y}\ket{y},
\end{equation}
which is just an equally weighted superposition of states
$\ket{y}$ such that $a\cdot y = 0$.
A measurement of the state in the first register will yield
any one of these states with equal likelihood.  Now, simply
repeat the entire algorithm $n$ times, each time obtaining
a particular value of $y$, say $y_i$ for trial $i$.
Then, solve the set of equations
\begin{equation}
\begin{split}
a\cdot y_1 =&\, 0\\
a\cdot y_2 =&\, 0\\
\vdots\quad&\\
a\cdot y_n =&\, 0\\
\end{split}
\end{equation}
for $a$.




%--------------------------------------------------------------------------------   
%--------------------------------------------------------------------------------   
\section{Prime Factorization}

Shor\dots

Braunstein\cite{Braunstein:96} has an excellent overview of Shor's algorithm,
along with more detailed accounts by\dots

The goal of the algorithm is to factor an integer $N$.
For the first step, randomly choose an integer $x$ that
is relatively prime to $N$.  If $x$ and $N$ did share a 
factor, Euclid's algorithm could be used to efficiently 
reduce the problem to a simpler one.

Next, consider the function
\begin{equation}
f(a) = x^a\pmod{N}.
\label{e:shorfunc}
\end{equation}
The first few evaluations of this function will look like
\begin{equation}
\begin{split}
1,x,\ldots,x^{r-1},             &\,x^r,x^{r+1},\ldots\\
\underbrace{1,x,\ldots,x^{r-1},}_{\text{r terms}}
&\underbrace{1^{\phantom{x}},x^{\phantom{r-1}},\ldots,\phantom{x^{r-1},}}_{\text{r terms}}
\underbrace{ 1,x,\ldots\phantom{,x^{r-1},}}_{\text{r terms}},
\end{split}
\end{equation}
where the top row is just $f(a)$ and the bottom is reduced modulo $N$.
The period of this function is just $r$.  This period is difficult to
obtain classically -- requiring many function evaluations until a pattern
is recognizable.  However, Shor's algorithm can efficiently compute this
period.  What does this period have to do with factoring $N$?

In this algorithm, consider only even periods $r$.
For randomly chosen $x$, the period $r$ of the function (\ref{e:shorfunc})
will be even fifty percent of the time.  If $r$ is odd, start over with
a new (randomly chosen) $x$.  This should not take too many 
tries\cite{Shor:94,Ekert/Jozsa:96}.

The (now even) period $r$ is just the smallest number such that
\begin{equation}
x^r\equiv 1\pmod{N}.
\end{equation}
Rewrite this as the difference of squares
\begin{equation}
\left(x^\frac{r}{2}\right)^2 - 1 \equiv 0\pmod{N},
\end{equation}
so that
\begin{equation}
\left(x^\frac{r}{2} + 1\right)
\left(x^\frac{r}{2} - 1\right)
\equiv 0\pmod{N}.
\label{e:product}
\end{equation}
This says one or the other of the factors in the product on the left 
hand side of (\ref{e:product}) share a factor with $N$.  So, just
compute\footnote{ 
\emph{Efficient} classical algorithms exist to compute the greatest
common divisor of two numbers\cite{Hardy/Wright:79}.
}
\begin{equation}
\gcd
\left(x^\frac{r}{2} + 1, N \right)
\end{equation}
and
\begin{equation}
\gcd
\left(x^\frac{r}{2} - 1, N \right).
\end{equation}
Any non--trivial divisor will be a factor of $N$.

%--------------------------------------------------------------------------------   
\subsection{Shor's Algorithm}

How can a quantum circuit find the period of a function
such as (\ref{e:shorfunc})?  First, the algorithm starts
with two $n$--bit zero--registers
\begin{equation}
\ket{0}\ket{0}.
\end{equation}
Next, as probably anticipated by now, comes a Hadamaard
transformation on the first register 
\begin{equation}
\left( H\otimes 1 \right) \ket{0}\ket{0}
\end{equation}
leaving
\begin{equation}
\frac{1}{\sqrt{2^n}}\sum_{x=0}^{2^n-1} \ket{x}\ket{0}.
\label{e:step2}
\end{equation}
Now, construct the unitary operator
\begin{equation}
U_f\colon\ket{x}\ket{0}\to\ket{x}\ket{f(x)}
\end{equation}
that evaluates the function
\begin{equation}
f(a) = x^a\pmod{N}.
\end{equation}
Act with this operator on (\ref{e:step2}) to get
\begin{equation}
U_f \left( \sum_{x} \ket{x}\ket{0} \right)
= \sum_{x} \ket{x}\ket{f(x)}.
\end{equation}
The quantum registers are now entangled\dots operations on
one will affect the other.  For the next step, 
perform a measurement 
\begin{equation}
1\otimes \ketbra{c}{c}
\end{equation}
on the second register to get
\begin{equation}
%\frac{1}{\sqrt{2^n}} \sum_x \ket{x}\ket{c}.
\sum_x \ket{x}\ket{c}.
\end{equation}
This has collapsed the first register into an equally weighted
superposition of states $\ket{x}$ such that 
$f(x) = c$.  All that's needed is the period of the function
$f$, so why not simply Fourier transform the first register
to determine the period?



%--------------------------------------------------------------------------------   
%--------------------------------------------------------------------------------   
\section{Searching a Quantum Database}
\label{sec:grover}

As discussed in section (\ref{sec:quantCompAlgs}), Grover's algorithm is
a version of the ubiquitous searching algorithm that will run on a quantum
computer.  Consider the {\sl quantum} solution to a simple search problem of 
the following form: A
single item is searched for in a set, a \emph{database}, of unordered items.  
This item is guaranteed to be listed in the database exactly once, but 
the location of the item within the database is unknown.

Items in the database can be enumerated by the states of a quantum system.
In particular, a database containing $N$ items can be represented by an
$N$--state system consisting of $n=\log(N)$ coupled 2--state systems
\begin{equation}
\ket{\Psi} = \sum_{i=0}^{2^N-1} a_i\ket{i}.
\end{equation}
This representation, discussed at great
length in chapter (\ref{chap:quantumComputation}),
should be quite familiar to the reader by now.
A simple quantum algorithm to ``search'' this quantum database
for a particular item consists of unitary evolution that amplifies 
the probability of finding the resultant state in the \emph{desired}
direction while simultaneously suppressing the probabilities for all
other components. \ie, for the expansion
\begin{equation}
\ket{\Psi} = a_{\text{desired}}\ket{\text{desired}} +
\sum_{i\ne\text{desired}} a_i\ket{i},
\end{equation}
the search algorithm would consist of a unitary operator that took
$a_{\text{desired}}\mapsto 1$ while $a_{\text{all others}}\mapsto 0$.

Grover's algorithm consists of a set of unitary operators that
{\sl approximately} accomplish the task described above in 
$O(\sqrt{N})$ iterations.   


%--------------------------------------------------------------------------------   
\subsection{The Algorithm}

Grover's algorithm is briefly outlined in figure (\ref{fig:grover}).
\begin{figure}[h]
\shabox{
    \begin{minipage}{13cm}
        \begin{center}
        \textbf{Grover's Quantum Search Algorithm}
        \end{center}
        \begin{enumerate}
            \item First, start with an equally weighted superposition $\ket{S}$
            of all possible states.
            \item Next, repeat the following sequence $O(\sqrt{N})$ 
            times\footnote{exactly when to stop is important here.}:
            \begin{enumerate}
                \item Query the oracle.  Given any state $\ket{S}$, rotate  
                the phase of the component in the direction of the desired state
                by $\pi$ radians.
                \item Flip the state about its ``average'' by applying
                what Grover refers to as the diffusion transform, $D\ket{S}$.
                \label{fig:grover:diffusion}
            \end{enumerate}
            \item Finally, measure the resulting state.  This should be the
            desired state with probability of at least $\frac{1}{2}$.
        \end{enumerate}
    \end{minipage}
}
\caption{An overview of Grover's algorithm.}
\label{fig:grover}
\end{figure}
In the first step, an equally weighted superposition of all possible
states is, of course, obtained by hitting the $n$-dimensional zero 
register with the Hadamaard transformation
\begin{equation}
H\ket{0} = \frac{1}{\sqrt{2^n}}\sum_{x=0}^{2^n-1}\ket{x} 
= 
  \left[ \begin{matrix}
            \frac{1}{\sqrt{2^n}}\\
            \frac{1}{\sqrt{2^n}}\\
            \vdots\\
            \frac{1}{\sqrt{2^n}}
         \end{matrix} 
  \right].
\label{e:groverStart}
\end{equation}
The numbers in the $2^n$--dimensional column vector on the right 
of equation (\ref{e:groverStart}) are the (now equal) weights of each 
of the $2^n$ basis vectors for $\Z_2^n$ that make up the state of the
register.
For simplicity, write $N=2^n$ so that
\begin{equation}
H\ket{0} = \frac{1}{\sqrt{N}}\sum_{x=0}^{N-1}\ket{x} 
= \left[ \begin{matrix}
            \frac{1}{\sqrt{N}}\\
            \frac{1}{\sqrt{N}}\\
            \vdots\\
            \frac{1}{\sqrt{N}}
         \end{matrix} 
  \right].
\end{equation}

\subsubsection{The Oracle}

The concept of an \emph{oracle} in step (2a) of figure (\ref{fig:grover}) 
can be confusing at first glance.  The idea is that there are criteria
by which the search algorithm decides that the desired item has been found.
This is often thought of in terms of a function
\begin{equation}
f\colon\quad\lbrace\mbox{Search Domain}\rbrace\quad\mapsto\quad\lbrace Y,N\rbrace,
\end{equation}
that obtains a ``yes'' result for only a single {\sl desired} input.
Of course, this function will look a little more like 
\begin{equation}
f\colon\quad\lbrace 0,1\rbrace^n\quad\mapsto\quad\lbrace 0,1\rbrace
\end{equation}
for a search domain consisting of $N=2^n$ inputs.
When the details of this function evaluation are known, searches can
be optimized accordingly.  On the other hand, when this function is 
evaluated as a \emph{black box}, where nothing is known about the function 
except perhaps bounds on the complexity of evaluation, then this is 
considered an \textbf{oracle query}.
\index{oracle query}

In classical searches, the decision function might be something like
a lexicographical 
compare of each name on file folders to some desired name.  
This function might also be treated classically as a black 
box \mmm{example}.

For Grover's algorithm, the decision function is evaluated as a black box.
Nothing is known about the function evaluation except that it will be
implemented via some quantum circuit like that introduced by the 
Deutsch--Josza algorithm (section \ref{ss:deutschJosza}).
How can this be implemented physically if nothing is known about the 
function evaluation? 
Consider the query of the oracle in Grover's algorithm:
\begin{quote}
Query the oracle.  Given any state $\ket{S}$, rotate  
the phase of the component in the direction of the desired state
by $\pi$ radians.
\end{quote}
Denote the desired state in the search by $\ket{\omega}$.
Any state can then be expanded in terms of $\ket{\omega}$ 
and everything else $\ket{\omega_\perp}$ as 
\begin{equation}
\ket{S} = \ket{\omega}\braket{\omega}{S} + 
             \ket{\omega_\perp}\braket{\omega_\perp}{S}.
\end{equation}
The oracle query ${\bf U_\omega}$ acting on $\ket{S}$
\begin{equation}
{\bf U_\omega}\ket{S} = \biggl( {\bf 1} - 2\ketbra{\omega}{\omega} \biggr) \ket{S}
\label{e:oracle}
\end{equation}
simply flips the state $\ket{S}$ about the (hyper)plane
spanned by $\ket{\omega_\perp}$.  \ie, The phase of the
component of the state in the direction of the desired
state is rotated by $\pi$ radians (see figure 
(\ref{fig:phaseFlip})).  
The resulting state will look like
\begin{equation}
{\bf U_\omega}\ket{S} =
\biggl( {\bf 1} - 2\ketbra{\omega}{\omega} \biggr) \ket{S}
= - \ket{\omega}\braket{\omega}{S} + 
             \ket{\omega_\perp}\braket{\omega_\perp}{S}.
\end{equation}
%\begin{figure}[h]
%\begin{center}
%\begin{picture}(150,150)
%    \thicklines
%    \path(0,0)(20,50)
%    \path(20,50)(150,70)
%    \path(150,70)(130,20)
%    \path(130,20)(0,0)
%    \put(75,35){\vector(-1,4){20}}
%    \put(20,20){$\ket{\omega_\perp}$}
%    \put(65,100){$\ket{\omega}$}
%    \put(140,90){$\ket{S}$}
%    \put(75,35){\vector(1,1){60}}
%    \put(75,35){\vector(3,-2){70}}
%\end{picture}
%\caption{The oracle query in Grover's algorithm reflects the state $\ket{S}$ through the
%plane $\ket{\omega_\perp}$.}
%\label{fig:phaseFlip}
%\end{center}
%\end{figure}
\begin{figure}[h]
\begin{center}
\begin{picture}(150,150)
    \thicklines
    \path(0,0)(20,50)
    \path(20,50)(150,70)
    \path(150,70)(130,20)
    \path(130,20)(0,0)
    \put(75,35){\vector(-1,4){20}}
    \put(20,20){$\ket{\omega_\perp}$}
    \put(65,100){$\ket{\omega}$}
    \put(140,90){$\ket{S}$}
    \put(145,-5){${\bf U_\omega}\ket{S}$}
    \put(75,35){\vector(1,1){60}}
    \dashline[+30]{3}[80](75,35)(102,16)
    \put(102,16){\vector(3,-2){40}}
\end{picture}
\caption{The oracle query in Grover's algorithm reflects the state $\ket{S}$ through the
plane $\ket{\omega_\perp}$.}
\label{fig:phaseFlip}
\end{center}
\end{figure}
Note that this operation can be implemented without knowing exactly
where $\ket{\omega}$ is in the state expansion.  This operation
still works despite the fact that it's not possible to write this
down in terms of a matrix such as
\begin{equation}
{\bf U_\omega}\ket{S} =
\begin{bmatrix}
    1       &0      &\cdots &      &0  \\
    0       &\ddots &       &      &   \\
    \vdots  &       &e^{i\pi}&     &\vdots   \\
            &       &       &\ddots&   \\
    0       &       &\cdots &      &1  \\
\end{bmatrix}
\begin{bmatrix}
            \frac{1}{\sqrt{N}}\\
            \vdots\\
            \frac{1}{\sqrt{N}}\\
            \vdots\\
            \frac{1}{\sqrt{N}}
\end{bmatrix}
=
\begin{bmatrix}
            \frac{1}{\sqrt{N}}\\
            \vdots\\
            -\frac{1}{\sqrt{N}}\\
            \vdots\\
            \frac{1}{\sqrt{N}}
\end{bmatrix},
\end{equation}
because you don't initially know where to put the phase shift.
This is not a problem because it \emph{is} possible to write an
algorithm, even classically, that examines each input and tests
for successful (``yes'') function evaluation.  This issue
has already been resolved by simply writing the
transformation as the operator 
\begin{equation}
{\bf U_\omega} = \bigl( {\bf 1} - 2\ketbra{\omega}{\omega} \bigr).
\end{equation}


\subsubsection{Inversion About the Average}
\label{ssec:diffusion}

Step (\ref{fig:grover:diffusion}) of Grover's algorithm
(figure \ref{fig:grover}) is an inversion of the state about
the {\sl average} state.  This so called 
\emph{diffusion transformation}
can be written
\begin{equation}
{\bf U_s} = 2\ketbra{s}{s} - {\bf 1},
\label{e:diffusion}
\end{equation}
where, as before, 
\begin{equation}
\ket{s} = \frac{1}{\sqrt{N}}\sum_{i=0}^{N-1} \ket{i}
\end{equation}
is the equally--weighted
superposition (the ``average'') of all computational basis states.
The diffusion transformation preserves $\ket{s}$, but flips 
the sign of any vector orthogonal to $\ket{s}$\dots
it \emph{rotates} a vector around $\ket{s}$.

Now, rewrite (\ref{e:diffusion}) as
\begin{equation}
\begin{split}
{\bf U_s} =& \frac{2}{N}\sum_{i,j} \ketbra{i}{j} - {\bf 1}\\
=& \frac{2}{N}\begin{pmatrix}
                    1 & 1 & \cdots & 1 \\
                    1 & 1 & &  \\
                    \vdots &  & \ddots & \vdots \\
                    1 & \cdots && 1 
              \end{pmatrix} - {\bf 1} \\
=& \begin{pmatrix}
    \frac{2-N}{N} & \frac{2}{N} & \cdots & \frac{2}{N} \\
    \frac{2}{N}   & \frac{2-N}{N} & &  \\
    \vdots &  & \ddots & \vdots \\
    \frac{2}{N}   & \cdots && \frac{2-N}{N} 
\end{pmatrix}.
\end{split}
\end{equation}

Each iteration in Grover's algorithm can be written as
the unitary transformation
\begin{equation}
{\bf U}_{\text{Grover}} = {\bf U}_s {\bf U}_\omega,
\end{equation}
which is just a query of the oracle followed by a flip
about the average.
This combined unitary operator cannot be written in matrix
form (because of ${\bf U_\omega}$), but the effect upon
the input state can be calculated.
Consider the state
\begin{equation}
\ket{\Psi} = k\ket{\omega} + l\ket{\omega_\perp}.
\end{equation}
A single Grover iteration applied to this state
gives
\begin{equation}
\begin{split}
{\bf U}_{\text{Grover}}\ket\Psi
\quad =&\quad  {\bf U_s}{\bf U_\omega} \left(
                k\ket{\omega} + l\ket{\omega_\perp}
             \right) \\
=&\quad  {\bf U_s} \left(
               -k\ket{\omega} + l\ket{\omega_\perp}
             \right) \\
=&\quad \bigl\lbrace 2\ketbra{s}{s} - {\bf 1} \bigr\rbrace
             \left(
                -k\ket{\omega} + l\ket{\omega_\perp}
             \right) \\
=&\quad \biggl\lbrace 
                    \frac{2}{N} \sum_{i,j}\ketbra{i}{j}
                    - {\bf 1} \biggr\rbrace
             \left(
                -k\ket{\omega} + l\ket{\omega_\perp}
             \right) \\
=&\quad 
                k\ket{\omega} - l\ket{\omega_\perp}
                + \frac{2}{N} \sum_{i,j} \biggl\lbrace
                                    - k\ket{i}\braket{j}{\omega}
                                    + l\ket{i}\braket{j}{\omega_\perp}
                              \biggr\rbrace \\
=&\quad 
                k\ket{\omega} - l\ket{\omega_\perp}
                + \frac{2}{N} \sum_i \ket{i} \biggl\lbrace
                                    - k\sum_j\braket{j}{\omega}
                                    + l\sum_j\braket{j}{\omega_\perp}
                              \biggr\rbrace.
\end{split}
\end{equation}
Since the ket $\ket\omega$ was chosen to be an element of the orthonormal
basis $\ket{i}$,
\begin{equation}
\sum_j \braket{j}{\omega} = 1,\qquad\text{and}\qquad
\sum_j \braket{j}{\omega_\perp} = N-1.
\end{equation}
A single step of Grover then looks like
\begin{equation}
{\bf U}_{\text{Grover}}\ket\Psi
\quad =\quad 
                k\ket{\omega} - l\ket{\omega_\perp}
                + \frac{2}{N} \sum_i \ket{i} \left(
                                    - k + l(N-1)
                              \right).
\end{equation}
To find the coefficients for the resulting state after 
the Grover iteration is applied, take
\begin{equation}
\begin{split}
k_{\text{new}} =& \bra{\omega}{\bf U}_{\text{Grover}}\ket\Psi\\
=& k\braket{\omega}{\omega} + \frac{2}{N} \left( -k + l(N-1) \right)
\braket{\omega}{\omega}\\
=& \frac{N-2}{N}k + \frac{2(N-1)}{N}l
\end{split}
\end{equation}
and 
\begin{equation}
\begin{split}
l_{\text{new}} =& \bra{\omega_\perp}{\bf U}_{\text{Grover}}\ket\Psi\\
=& -l\braket{\omega_\perp}{\omega_\perp}
+ \frac{2}{N} \left( -k + l(N-1) \right) \braket{\omega_\perp}{\omega_\perp}\\
=& -\frac{2}{N}k + \frac{N-2}{N}l.
\end{split}
\end{equation}
So, under the action of Grover's algorithm, the state at any given
iteration can be described by
\begin{equation}
\ket{\Psi_i} = k_i\ket{\omega} + l_i\ket{\omega_\perp},
\end{equation}
where $k_i$ and $l_i$ are determined iteratively by
\begin{equation}
\begin{split}
k_{i+1} =& \frac{N-2}{N}k_i + \frac{2(N-1)}{N}l_i\\
l_{i+1} =& -\frac{2}{N}k_i + \frac{N-2}{N}l_i.
\end{split}
\end{equation}



                
\subsubsection{Measurement}

The final step in Grover's algorithm is simply to measure the
resulting state after the appropriate number of iterations.
The desired state should then be measured with probability of at
least $\frac{1}{2}$.
A careful analysis of this is presented in the following section.

%--------------------------------------------------------------------------------   
\subsection{Complexity Analysis}

\subsubsection{A Classical Search}

In order to understand the complexity of Grover's algorithm,
it is useful to discuss the complexity associated with a 
similar search on a classical computer.

The relevant clasical search problem is as follows:  
start with a large unsorted database containing $N>>1$ items.
Find one particular item in this database\dots
search for a ``needle in a haystack'' as Grover puts
it\cite{Grover:96}.  As discussed earlier, this database can 
be represented by a table or a function $f(x)$ where
$x\in\lbrace 0,1,\ldots,N-1\rbrace$.
The item searched for is guaranteed to be in the database
exactly once, so $f(x)=a$ for only a single 
value of $x$. Now, given $a$, find $x$.

If the database has been sorted, $x$ can be found by 
evaluating the function for only $\log N$ possible 
values of the domain before the value $a$ is obtained.

Suppose $N$ is a power of 2, say $N=2^n$.  Then the search
would start by evaluating $f(x)$ for $x=2^{n-1}-1$,
and then comparing the result to the desired result, $a$.
If $f(x)$ is greater than $a$, then repeat the search
step by evaluating $f(x)$ on $x=2^{n-2}-1$ and comparing,
etc.  

Consider, for a nice concrete example, a database consisting
of file folders.  The oracle function $f$ is simply to read
the name on the folder, the value of the desired folder being
the name $a$.  If the database is ordered, lexicographically say,
then the search would start by grabbing the middle folder
($x=2^n-1$), reading the name on the folder (evaluating the
function $f$), and then comparing this name to the name $a$.
If the name $a$ is later in the list, choose a folder three
quarters of the way back and try again.  In a worst--case
scenario, you will have to look at $\log_2 N$ different 
folders to find the one with the name $a$.  
Another example of this kind of search
is, knowing a person's name, looking up their phone number in
the phone book.  These are all searches of an ordered database.

On the other hand, if the database is not ordered the search
becomes much more difficult.  Take, for instance, the seemingly
intractable problem of using the phone book to look up a 
person's name given their phone number.  This is essentially
looking for an item in an unordered list -- searching for a 
needle in a haystack.  Considerably more function evaluations
would be required in this instance.  It requires $\frac{N}{2}$
lookups or evaluations before the probability of success is 
greater than $\frac{1}{2}$.


\subsubsection{Grover}

\mmm{probability of measuring desired state as a function of
number of iterations}

\subsubsection{Grover is Optimal}

\mmm{Zalka says Grover is least time...}

%--------------------------------------------------------------------------------   
\subsection{Advanced Searches}

\subsubsection{Multisearch}

\subsubsection{Start from an Arbitrary Initial Distribution}


%--------------------------------------------------------------------------------   
%--------------------------------------------------------------------------------   
\section{Developing New Quantum Algorithms}

NP--Complete?
